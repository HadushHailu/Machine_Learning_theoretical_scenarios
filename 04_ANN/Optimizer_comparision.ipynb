{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7f3ba7b3-5452-4221-b4fa-c83328346c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "91265b7e-11e2-40f7-87c7-58700ea850a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-06 08:01:56.609008: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 08:01:56.831293: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-05-06 08:01:56.832953: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-06 08:01:57.670656: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training with optimizer: adam, epochs: 5, batch_size: 32\n",
      "Test accuracy: 0.9246000051498413\n",
      "Training with optimizer: adam, epochs: 5, batch_size: 64\n",
      "Test accuracy: 0.9277999997138977\n",
      "Training with optimizer: adam, epochs: 5, batch_size: 128\n",
      "Test accuracy: 0.9276000261306763\n",
      "Training with optimizer: adam, epochs: 10, batch_size: 32\n",
      "Test accuracy: 0.9261000156402588\n",
      "Training with optimizer: adam, epochs: 10, batch_size: 64\n",
      "Test accuracy: 0.9282000064849854\n",
      "Training with optimizer: adam, epochs: 10, batch_size: 128\n",
      "Test accuracy: 0.9273999929428101\n",
      "Training with optimizer: adam, epochs: 20, batch_size: 32\n",
      "Test accuracy: 0.9277999997138977\n",
      "Training with optimizer: adam, epochs: 20, batch_size: 64\n",
      "Test accuracy: 0.9272000193595886\n",
      "Training with optimizer: adam, epochs: 20, batch_size: 128\n",
      "Test accuracy: 0.9265999794006348\n",
      "Training with optimizer: sgd, epochs: 5, batch_size: 32\n",
      "Test accuracy: 0.927299976348877\n",
      "Training with optimizer: sgd, epochs: 5, batch_size: 64\n",
      "Test accuracy: 0.9262999892234802\n",
      "Training with optimizer: sgd, epochs: 5, batch_size: 128\n",
      "Test accuracy: 0.926800012588501\n",
      "Training with optimizer: sgd, epochs: 10, batch_size: 32\n",
      "Test accuracy: 0.9269999861717224\n",
      "Training with optimizer: sgd, epochs: 10, batch_size: 64\n",
      "Test accuracy: 0.9266999959945679\n",
      "Training with optimizer: sgd, epochs: 10, batch_size: 128\n",
      "Test accuracy: 0.9269000291824341\n",
      "Training with optimizer: sgd, epochs: 20, batch_size: 32\n",
      "Test accuracy: 0.9265000224113464\n",
      "Training with optimizer: sgd, epochs: 20, batch_size: 64\n",
      "Test accuracy: 0.926800012588501\n",
      "Training with optimizer: sgd, epochs: 20, batch_size: 128\n",
      "Test accuracy: 0.926800012588501\n",
      "Training with optimizer: rmsprop, epochs: 5, batch_size: 32\n",
      "Test accuracy: 0.9291999936103821\n",
      "Training with optimizer: rmsprop, epochs: 5, batch_size: 64\n",
      "Test accuracy: 0.9265000224113464\n",
      "Training with optimizer: rmsprop, epochs: 5, batch_size: 128\n",
      "Test accuracy: 0.9273999929428101\n",
      "Training with optimizer: rmsprop, epochs: 10, batch_size: 32\n",
      "Test accuracy: 0.9273999929428101\n",
      "Training with optimizer: rmsprop, epochs: 10, batch_size: 64\n",
      "Test accuracy: 0.9247000217437744\n",
      "Training with optimizer: rmsprop, epochs: 10, batch_size: 128\n",
      "Test accuracy: 0.9265000224113464\n",
      "Training with optimizer: rmsprop, epochs: 20, batch_size: 32\n",
      "Test accuracy: 0.9254999756813049\n",
      "Training with optimizer: rmsprop, epochs: 20, batch_size: 64\n",
      "Test accuracy: 0.9261999726295471\n",
      "Training with optimizer: rmsprop, epochs: 20, batch_size: 128\n",
      "Test accuracy: 0.9253000020980835\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n",
    "\n",
    "# Normalize the images to have pixel values between 0 and 1\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoded vectors\n",
    "train_labels = to_categorical(train_labels)\n",
    "test_labels = to_categorical(test_labels)\n",
    "\n",
    "# Define the model architecture\n",
    "model = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),  # Flattens the input\n",
    "    Dense(10, activation='softmax')  # A softmax layer with 10 output units for each digit\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Define the different numbers of epochs and batch sizes to try\n",
    "epochs_list = [5, 10, 20]\n",
    "batch_sizes = [32, 64, 128]\n",
    "\n",
    "# Define the different optimizers to try\n",
    "optimizers = ['adam', 'sgd', 'rmsprop']\n",
    "\n",
    "for optimizer in optimizers:\n",
    "    for epochs in epochs_list:\n",
    "        for batch_size in batch_sizes:\n",
    "            # Compile the model\n",
    "            model.compile(optimizer=optimizer,\n",
    "                          loss='categorical_crossentropy',\n",
    "                          metrics=['accuracy'])\n",
    "            \n",
    "            # Train the model\n",
    "            print(f\"Training with optimizer: {optimizer}, epochs: {epochs}, batch_size: {batch_size}\")\n",
    "            model.fit(train_images, train_labels, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "            \n",
    "            # Evaluate the model\n",
    "            test_loss, test_acc = model.evaluate(test_images, test_labels, verbose=0)\n",
    "            print(f'Test accuracy: {test_acc}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92659e9e-90fd-4fba-875e-316f2638a5e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
